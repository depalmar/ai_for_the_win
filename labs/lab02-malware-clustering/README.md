# Lab 02: Malware Sample Clustering

Use unsupervised learning to cluster malware samples by behavior and characteristics.

---

## ðŸŽ¯ Learning Objectives

By completing this lab, you will:

1. Extract features from malware samples (static analysis)
2. Apply dimensionality reduction techniques
3. Use clustering algorithms (K-Means, DBSCAN)
4. Visualize malware families
5. Identify new malware variants

---

## â±ï¸ Estimated Time

60-75 minutes (with AI assistance)

---

## ðŸ“‹ Prerequisites

- Completed Lab 01
- Understanding of clustering concepts
- Python environment with ML libraries

### Required Libraries

```bash
pip install scikit-learn pandas numpy matplotlib seaborn
pip install pefile yara-python  # For PE analysis
```

---

## ðŸ“– Background

### Why Cluster Malware?

- **Family Identification**: Group samples by malware family
- **Variant Detection**: Find new variants of known malware
- **Threat Attribution**: Link samples to threat actors
- **Prioritization**: Focus analysis on unique samples

### Feature Extraction Approaches

| Feature Type | Examples | Use Case |
|--------------|----------|----------|
| Static | Import hash, section names, strings | Quick triage |
| Behavioral | API calls, network activity, file ops | Dynamic analysis |
| Structural | PE headers, entropy, size | Packer detection |

---

## ðŸ”¬ Lab Tasks

### Task 1: Load Sample Data (10 min)

Load and explore the malware feature dataset:

```python
def load_malware_data(filepath: str) -> pd.DataFrame:
    """
    Load pre-extracted malware features.

    Features include:
    - file_size: Size in bytes
    - entropy: Shannon entropy
    - num_imports: Number of imported functions
    - num_sections: Number of PE sections
    - has_debug: Debug info present
    - has_signature: Digital signature present
    - imphash: Import hash (categorical)
    - api_categories: Encoded API category vector

    TODO:
    1. Load CSV file
    2. Handle missing values
    3. Print dataset statistics
    """
    pass
```

### Task 2: Feature Engineering (15 min)

Transform features for clustering:

```python
def engineer_features(df: pd.DataFrame) -> np.ndarray:
    """
    Prepare features for clustering.

    TODO:
    1. Select numeric features
    2. Handle categorical features (one-hot encoding)
    3. Normalize/standardize features
    4. Return feature matrix

    Consider:
    - Log transform for skewed features (file_size)
    - Standard scaling for clustering
    - Handle outliers
    """
    pass
```

### Task 3: Dimensionality Reduction (15 min)

Reduce dimensions for visualization:

```python
def reduce_dimensions(X: np.ndarray, method: str = 'pca') -> np.ndarray:
    """
    Reduce feature dimensions for visualization and clustering.

    Args:
        X: Feature matrix
        method: 'pca', 'tsne', or 'umap'

    Returns:
        2D representation

    TODO:
    1. Apply PCA for initial reduction
    2. Apply t-SNE or UMAP for visualization
    3. Return 2D coordinates
    """
    pass
```

### Task 4: Clustering (15 min)

Apply clustering algorithms:

```python
def cluster_samples(X: np.ndarray, method: str = 'kmeans') -> np.ndarray:
    """
    Cluster malware samples.

    Args:
        X: Feature matrix (or reduced features)
        method: 'kmeans', 'dbscan', or 'hierarchical'

    Returns:
        Cluster labels

    TODO:
    1. Determine optimal number of clusters (elbow method)
    2. Apply selected clustering algorithm
    3. Evaluate clustering quality (silhouette score)
    4. Return cluster labels
    """
    pass
```

### Task 5: Visualization (10 min)

Create visualizations:

```python
def visualize_clusters(X_2d: np.ndarray, labels: np.ndarray, family_labels: np.ndarray = None):
    """
    Visualize clustering results.

    TODO:
    1. Create scatter plot with cluster colors
    2. If family_labels provided, create comparison plot
    3. Add legend and labels
    4. Save high-quality figure
    """
    pass
```

### Task 6: Analysis (10 min)

Analyze clustering results:

```python
def analyze_clusters(df: pd.DataFrame, labels: np.ndarray) -> dict:
    """
    Analyze characteristics of each cluster.

    Returns:
        Dict with cluster statistics:
        - size: Number of samples
        - avg_entropy: Average entropy
        - common_imports: Most common import functions
        - suspected_family: Likely malware family

    TODO:
    1. Group samples by cluster
    2. Calculate statistics per cluster
    3. Identify distinguishing features
    4. Suggest family names
    """
    pass
```

---

## ðŸ“ Files

```
lab02-malware-clustering/
â”œâ”€â”€ README.md
â”œâ”€â”€ starter/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ solution/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ malware_features.csv    # Pre-extracted features
â”‚   â””â”€â”€ sample_info.csv         # Sample metadata
â””â”€â”€ output/
    â””â”€â”€ cluster_visualization.png
```

---

## ðŸ“Š Sample Dataset

```csv
sha256,file_size,entropy,num_imports,num_sections,has_debug,imphash,family
abc123...,245760,7.2,45,5,0,d4e5f6...,emotet
def456...,102400,6.8,32,4,0,a1b2c3...,trickbot
...
```

---

## âœ… Success Criteria

- [ ] Features normalized correctly
- [ ] Dimensionality reduction produces meaningful 2D plot
- [ ] Clustering finds 3-5 distinct groups
- [ ] Silhouette score > 0.3
- [ ] Visualization clearly shows cluster separation
- [ ] Analysis identifies likely malware families

---

## ðŸŽ¯ Expected Output

```
Clustering Results:
==================
Method: K-Means (k=4)
Silhouette Score: 0.42

Cluster 0 (n=156):
  - Avg entropy: 7.4
  - Avg size: 230KB
  - Common imports: VirtualAlloc, CreateRemoteThread
  - Suspected family: Cobalt Strike

Cluster 1 (n=89):
  - Avg entropy: 6.2
  - Avg size: 95KB
  - Common imports: InternetOpenUrl, HttpSendRequest
  - Suspected family: Banking Trojan

...
```

---

## ðŸš€ Bonus Challenges

1. **YARA Generation**: Create YARA rules for each cluster
2. **Dynamic Features**: Add behavioral features from sandbox reports
3. **Online Clustering**: Handle streaming new samples
4. **Outlier Detection**: Identify unique/novel samples
5. **Attribution**: Link clusters to known threat actors

---

## ðŸ’¡ Hints

Click to expand each hint when you get stuck. Try to solve each task on your own first!

### Task 1: Loading Data

<details>
<summary>Hint 1.1: Loading and handling missing values</summary>

```python
df = pd.read_csv(filepath)

# Handle numeric columns
numeric_cols = df.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    df[col] = df[col].fillna(df[col].median())

# Handle categorical columns
object_cols = df.select_dtypes(include=['object']).columns
for col in object_cols:
    df[col] = df[col].fillna('unknown')
```
</details>

### Task 2: Feature Engineering

<details>
<summary>Hint 2.1: Log transform for skewed features</summary>

```python
# File size is often highly skewed - use log transform
# np.log1p handles zero values safely (log(1+x))
df['file_size_log'] = np.log1p(df['file_size'])
```
</details>

<details>
<summary>Hint 2.2: Encoding categorical features</summary>

```python
from sklearn.preprocessing import LabelEncoder

# Encode categorical imphash to numeric
encoder = LabelEncoder()
df['imphash_encoded'] = encoder.fit_transform(df['imphash'])
```
</details>

<details>
<summary>Hint 2.3: Scaling features</summary>

```python
from sklearn.preprocessing import StandardScaler

feature_cols = ['file_size_log', 'entropy', 'num_imports', 'num_sections', 'imphash_encoded']
X = df[feature_cols].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

return X_scaled, feature_cols
```
</details>

### Task 3: Dimensionality Reduction

<details>
<summary>Hint 3.1: PCA reduction</summary>

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_2d = pca.fit_transform(X)
```
</details>

<details>
<summary>Hint 3.2: t-SNE for better visualization</summary>

```python
from sklearn.manifold import TSNE

# Good starting parameters for malware data
tsne = TSNE(
    n_components=2,
    perplexity=30,
    learning_rate=200,
    n_iter=1000,
    random_state=42
)
X_2d = tsne.fit_transform(X)
```
</details>

### Task 4: Clustering

<details>
<summary>Hint 4.1: Finding optimal K</summary>

```python
from sklearn.metrics import silhouette_score

scores = []
for k in range(2, 10):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    scores.append(silhouette_score(X, labels))

optimal_k = range(2, 10)[np.argmax(scores)]
```
</details>

<details>
<summary>Hint 4.2: KMeans vs DBSCAN</summary>

```python
# KMeans - when you know approximate number of clusters
labels = KMeans(n_clusters=k, random_state=42).fit_predict(X)

# DBSCAN - finds clusters automatically, good for outlier detection
labels = DBSCAN(eps=0.5, min_samples=5).fit_predict(X)
# Note: DBSCAN labels outliers as -1
```
</details>

### Task 5: Visualization

<details>
<summary>Hint 5.1: Scatter plot with clusters</summary>

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=labels, cmap='tab10', alpha=0.7)
plt.colorbar(scatter, label='Cluster')
plt.xlabel('Dimension 1')
plt.ylabel('Dimension 2')
plt.title('Malware Clusters')
plt.show()
```
</details>

### Task 6: Analysis

<details>
<summary>Hint 6.1: Analyzing cluster statistics</summary>

```python
df['cluster'] = labels
analysis = {}

for cluster_id in df['cluster'].unique():
    cluster_data = df[df['cluster'] == cluster_id]
    analysis[cluster_id] = {
        'size': len(cluster_data),
        'avg_entropy': cluster_data['entropy'].mean(),
        'avg_file_size': cluster_data['file_size'].mean(),
        'suspected_family': cluster_data['family'].mode()[0] if 'family' in df.columns else 'unknown'
    }
```
</details>

---

## ðŸ“š Resources

- [Scikit-learn Clustering](https://scikit-learn.org/stable/modules/clustering.html)
- [t-SNE Explained](https://distill.pub/2016/misread-tsne/)
- [Malware Feature Engineering](https://www.malwaretech.com/)
- [PE File Format](https://docs.microsoft.com/en-us/windows/win32/debug/pe-format)

---

> **Stuck?** See the [Lab 02 Walkthrough](../../docs/walkthroughs/lab02-walkthrough.md) for step-by-step guidance.

**Next Lab**: [Lab 03 - Anomaly Detection](../lab03-anomaly-detection/)
