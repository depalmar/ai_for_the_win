{
  "Pydantic Threat Model": {
    "prefix": "sec-pydantic",
    "body": [
      "from pydantic import BaseModel, Field",
      "from typing import Optional",
      "from datetime import datetime",
      "",
      "",
      "class ${1:ThreatIndicator}(BaseModel):",
      "    \"\"\"${2:Structured threat indicator model}.\"\"\"",
      "",
      "    ${3:indicator_type}: str = Field(..., description=\"${4:Type of indicator}\")",
      "    value: str = Field(..., description=\"The indicator value\")",
      "    confidence: float = Field(ge=0, le=1, default=0.5, description=\"Confidence score 0-1\")",
      "    mitre_techniques: list[str] = Field(default_factory=list)",
      "    first_seen: Optional[datetime] = None",
      "    last_seen: Optional[datetime] = None",
      "    tags: list[str] = Field(default_factory=list)",
      "",
      "    class Config:",
      "        json_schema_extra = {",
      "            \"example\": {",
      "                \"${3:indicator_type}\": \"${5:ip}\",",
      "                \"value\": \"192[.]168[.]1[.]1\",",
      "                \"confidence\": 0.85,",
      "                \"mitre_techniques\": [\"T1071\"],",
      "            }",
      "        }",
      "$0"
    ],
    "description": "Pydantic model for security/threat data"
  },

  "LangChain Security Agent": {
    "prefix": "sec-agent",
    "body": [
      "from langchain.agents import AgentExecutor, create_react_agent",
      "from langchain.tools import Tool",
      "from langchain_core.prompts import PromptTemplate",
      "from shared.llm_config import get_chat_model",
      "",
      "",
      "def create_${1:security}_agent(tools: list[Tool]) -> AgentExecutor:",
      "    \"\"\"Create a ${2:security-focused} ReAct agent.",
      "",
      "    Args:",
      "        tools: List of tools available to the agent.",
      "",
      "    Returns:",
      "        AgentExecutor ready to process queries.",
      "    \"\"\"",
      "    llm = get_chat_model(temperature=0)",
      "",
      "    prompt = PromptTemplate.from_template(",
      "        \"\"\"You are a ${2:security-focused} AI assistant.",
      "",
      "Available tools: {tools}",
      "Tool names: {tool_names}",
      "",
      "Question: {input}",
      "Thought: {agent_scratchpad}\"\"\"",
      "    )",
      "",
      "    agent = create_react_agent(llm, tools, prompt)",
      "",
      "    return AgentExecutor(",
      "        agent=agent,",
      "        tools=tools,",
      "        verbose=True,",
      "        handle_parsing_errors=True,",
      "        max_iterations=10,",
      "    )",
      "$0"
    ],
    "description": "LangChain ReAct agent template for security tasks"
  },

  "YARA Rule Template": {
    "prefix": "sec-yara",
    "body": [
      "rule ${1:RuleName} {",
      "    meta:",
      "        author = \"${2:Your Name}\"",
      "        description = \"${3:Detects suspicious behavior}\"",
      "        date = \"${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}\"",
      "        reference = \"${4:https://}\"",
      "        mitre_attack = \"${5:T1059}\"",
      "        severity = \"${6|high,medium,low|}\"",
      "",
      "    strings:",
      "        \\$${7:string1} = \"${8:pattern}\" ${9|ascii,wide,nocase|}",
      "        \\$${10:hex1} = { ${11:DE AD BE EF} }",
      "",
      "    condition:",
      "        ${12:any of them}",
      "}",
      "$0"
    ],
    "description": "YARA rule with metadata and MITRE mapping"
  },

  "Pytest Security Test": {
    "prefix": "sec-test",
    "body": [
      "import pytest",
      "from unittest.mock import Mock, patch",
      "",
      "",
      "class Test${1:FeatureName}:",
      "    \"\"\"Tests for ${2:feature description}.\"\"\"",
      "",
      "    @pytest.fixture",
      "    def ${3:sample_data}(self) -> dict:",
      "        \"\"\"Fixture providing test data.\"\"\"",
      "        return {",
      "            \"${4:key}\": \"${5:value}\",",
      "        }",
      "",
      "    def test_${6:valid_input}(self, ${3:sample_data}: dict) -> None:",
      "        \"\"\"Test ${7:normal operation}.\"\"\"",
      "        result = ${8:function_under_test}(${3:sample_data})",
      "        assert result is not None",
      "        ${0:# Add assertions}",
      "",
      "    def test_${9:invalid_input}_raises(self) -> None:",
      "        \"\"\"Test that invalid input raises appropriate error.\"\"\"",
      "        with pytest.raises(${10:ValueError}):",
      "            ${8:function_under_test}(None)",
      "",
      "    @pytest.mark.requires_api",
      "    def test_${11:api_integration}(self) -> None:",
      "        \"\"\"Integration test requiring API key.\"\"\"",
      "        pytest.skip(\"Requires API key - set marker to run\")"
    ],
    "description": "Pytest test class with fixtures and markers"
  },

  "IOC Defanger": {
    "prefix": "sec-defang",
    "body": [
      "import re",
      "",
      "",
      "def defang_ioc(ioc: str, ioc_type: str = \"auto\") -> str:",
      "    \"\"\"Defang an IOC for safe handling.",
      "",
      "    Args:",
      "        ioc: The indicator of compromise to defang.",
      "        ioc_type: Type hint (url, ip, domain, auto).",
      "",
      "    Returns:",
      "        Defanged IOC string.",
      "    \"\"\"",
      "    if ioc_type == \"auto\":",
      "        if ioc.startswith((\"http://\", \"https://\")):",
      "            ioc_type = \"url\"",
      "        elif re.match(r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\", ioc):",
      "            ioc_type = \"ip\"",
      "        else:",
      "            ioc_type = \"domain\"",
      "",
      "    if ioc_type == \"url\":",
      "        return ioc.replace(\"http://\", \"hxxp://\").replace(\"https://\", \"hxxps://\")",
      "    elif ioc_type == \"ip\":",
      "        return ioc.replace(\".\", \"[.]\")",
      "    elif ioc_type == \"domain\":",
      "        return ioc.replace(\".\", \"[.]\")",
      "",
      "    return ioc",
      "$0"
    ],
    "description": "IOC defanging utility function"
  },

  "Async HTTP Client": {
    "prefix": "sec-async-client",
    "body": [
      "import httpx",
      "from typing import Any",
      "",
      "",
      "async def ${1:fetch_threat_data}(",
      "    ${2:endpoint}: str,",
      "    ${3:params}: dict[str, Any] | None = None,",
      "    timeout: float = 30.0,",
      ") -> dict[str, Any]:",
      "    \"\"\"${4:Fetch threat intelligence data from API}.",
      "",
      "    Args:",
      "        ${2:endpoint}: API endpoint URL.",
      "        ${3:params}: Optional query parameters.",
      "        timeout: Request timeout in seconds.",
      "",
      "    Returns:",
      "        JSON response as dictionary.",
      "",
      "    Raises:",
      "        httpx.HTTPError: On request failure.",
      "    \"\"\"",
      "    async with httpx.AsyncClient(timeout=timeout) as client:",
      "        response = await client.get(",
      "            ${2:endpoint},",
      "            params=${3:params},",
      "            headers={\"User-Agent\": \"SecurityTool/1.0\"},",
      "        )",
      "        response.raise_for_status()",
      "        return response.json()",
      "$0"
    ],
    "description": "Async HTTP client for API calls"
  },

  "MITRE ATT&CK Mapping": {
    "prefix": "sec-mitre",
    "body": [
      "# MITRE ATT&CK Technique Mapping",
      "MITRE_TECHNIQUES = {",
      "    \"${1:T1059.001}\": {",
      "        \"name\": \"${2:PowerShell}\",",
      "        \"tactic\": \"${3:Execution}\",",
      "        \"description\": \"${4:Adversaries may abuse PowerShell commands}\",",
      "        \"detection\": \"${5:Monitor for PowerShell execution}\",",
      "        \"url\": \"https://attack.mitre.org/techniques/${1:T1059.001}/\",",
      "    },",
      "    $0",
      "}"
    ],
    "description": "MITRE ATT&CK technique mapping dictionary"
  },

  "LLM Prompt Template": {
    "prefix": "sec-prompt",
    "body": [
      "from langchain_core.prompts import ChatPromptTemplate",
      "",
      "${1:SECURITY_ANALYSIS_PROMPT} = ChatPromptTemplate.from_messages([",
      "    (\"system\", \"\"\"You are a security analyst assistant.",
      "",
      "Your role is to ${2:analyze potential security threats}.",
      "",
      "Guidelines:",
      "- Always reference MITRE ATT&CK techniques when applicable",
      "- Defang all IOCs in your output (hxxp://, [.], etc.)",
      "- Provide actionable recommendations",
      "- Include confidence levels for your assessments",
      "",
      "Output format: ${3:JSON with structured findings}\"\"\"),",
      "    (\"human\", \"{${4:input}}\"),",
      "])",
      "$0"
    ],
    "description": "Security-focused LLM prompt template"
  },

  "ChromaDB RAG Setup": {
    "prefix": "sec-rag",
    "body": [
      "import chromadb",
      "from chromadb.config import Settings",
      "from langchain_community.vectorstores import Chroma",
      "from langchain_community.embeddings import HuggingFaceEmbeddings",
      "",
      "",
      "def create_security_vectorstore(",
      "    persist_directory: str = \"./chroma_db\",",
      "    collection_name: str = \"${1:security_docs}\",",
      ") -> Chroma:",
      "    \"\"\"Create a ChromaDB vectorstore for security documents.",
      "",
      "    Args:",
      "        persist_directory: Path to persist the database.",
      "        collection_name: Name of the collection.",
      "",
      "    Returns:",
      "        Chroma vectorstore instance.",
      "    \"\"\"",
      "    embeddings = HuggingFaceEmbeddings(",
      "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"",
      "    )",
      "",
      "    vectorstore = Chroma(",
      "        collection_name=collection_name,",
      "        embedding_function=embeddings,",
      "        persist_directory=persist_directory,",
      "    )",
      "",
      "    return vectorstore",
      "$0"
    ],
    "description": "ChromaDB setup for security RAG"
  },

  "Structured Output with Instructor": {
    "prefix": "sec-instructor",
    "body": [
      "import instructor",
      "from pydantic import BaseModel, Field",
      "from anthropic import Anthropic",
      "",
      "",
      "class ${1:ThreatAnalysis}(BaseModel):",
      "    \"\"\"Structured output for ${2:threat analysis}.\"\"\"",
      "",
      "    ${3:threat_type}: str = Field(description=\"${4:Type of threat detected}\")",
      "    confidence: float = Field(ge=0, le=1, description=\"Confidence score\")",
      "    mitre_techniques: list[str] = Field(default_factory=list)",
      "    recommendations: list[str] = Field(default_factory=list)",
      "",
      "",
      "def analyze_with_structure(${5:input_data}: str) -> ${1:ThreatAnalysis}:",
      "    \"\"\"Get structured analysis from LLM.\"\"\"",
      "    client = instructor.from_anthropic(Anthropic())",
      "",
      "    return client.chat.completions.create(",
      "        model=\"claude-sonnet-4-20250514\",",
      "        response_model=${1:ThreatAnalysis},",
      "        messages=[",
      "            {\"role\": \"user\", \"content\": f\"Analyze: {${5:input_data}}\"}",
      "        ],",
      "    )",
      "$0"
    ],
    "description": "Instructor structured output pattern"
  }
}
