{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 13: ML vs LLM - When to Use Which?\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/depalmar/ai_for_the_win/blob/main/notebooks/lab13_ml_vs_llm.ipynb)\n\nSolve the same security problem with both ML and LLM, then compare results.\n\n---\n\n## \ud83c\udf09 BRIDGE LAB: Transitioning from ML to LLM\n\n> **Where you are in the curriculum:**\n> - You've completed Labs 01-03 (ML track): classification, clustering, anomaly detection\n> - You trained models on YOUR data with YOUR labels\n> - Next up: Labs 04+ use Large Language Models (LLMs) via API calls\n>\n> **This lab bridges that gap** by showing you the same problem solved BOTH ways.\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    YOUR LEARNING JOURNEY                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                     \u2502\n\u2502   LABS 01-03 (ML)              THIS LAB (03b)           LABS 04+    \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500            \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 Train your  \u2502                                    \u2502 Call API  \u2502  \u2502\n\u2502   \u2502 own models  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba COMPARISON \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502 with your \u2502  \u2502\n\u2502   \u2502 on data     \u2502                 \ud83c\udf09                 \u2502 prompts   \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                     \u2502\n\u2502   - scikit-learn          - When ML wins             - anthropic/   \u2502\n\u2502   - .fit() / .predict()   - When LLM wins              openai SDK  \u2502\n\u2502   - Feature engineering   - Hybrid patterns          - API keys    \u2502\n\u2502   - Local models          - Cost/speed trade-offs    - Prompts     \u2502\n\u2502                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### Prerequisites\n- **Required**: Lab 29 (classification concepts), Lab 32 (anomaly detection)\n- **Helpful**: Lab 31 (prompt engineering basics)\n\n### Why This Lab Matters\n\nMany security teams struggle with this question: *\"Should we use ML or LLM for this?\"*\n\nThe answer is usually: **it depends** - and sometimes **both**.\n\nThis lab gives you hands-on experience with both approaches on the SAME problem, so you can make informed decisions in your own work.\n\n---\n\n## Learning Objectives\n- Understand when to use ML vs LLM for security tasks\n- Implement the same classifier with both approaches\n- Compare speed, cost, accuracy, and flexibility\n- Design hybrid systems that use both effectively\n\n## The Challenge\n\nYou're a SOC analyst receiving thousands of log entries. Your task: classify each as **malicious** or **benign**.\n\nWe'll solve this with **both approaches** and compare!\n\n**Next:** Lab 35 (LLM Log Analysis) - Start the LLM track!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install dependencies (Colab only)\n",
    "#@markdown Run this cell to install required packages in Colab\n",
    "\n",
    "%pip install -q scikit-learn numpy pandas anthropic openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"\u2705 Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Two Approaches\n",
    "\n",
    "### Approach 1: Traditional ML\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    ML CLASSIFICATION                         \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                             \u2502\n",
    "\u2502   Log Entry                                                 \u2502\n",
    "\u2502       \u2502                                                     \u2502\n",
    "\u2502       \u25bc                                                     \u2502\n",
    "\u2502   Feature Extraction                                        \u2502\n",
    "\u2502   \u251c\u2500\u2500 \"failed\" in text? \u2192 1                                \u2502\n",
    "\u2502   \u251c\u2500\u2500 \"login\" in text? \u2192 1                                 \u2502\n",
    "\u2502   \u251c\u2500\u2500 external IP? \u2192 1                                     \u2502\n",
    "\u2502   \u2514\u2500\u2500 suspicious keywords? \u2192 3                             \u2502\n",
    "\u2502       \u2502                                                     \u2502\n",
    "\u2502       \u25bc                                                     \u2502\n",
    "\u2502   [1, 1, 1, 3] \u2192 Model \u2192 0.87 \u2192 MALICIOUS                  \u2502\n",
    "\u2502                                                             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### Approach 2: LLM Classification\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    LLM CLASSIFICATION                        \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                             \u2502\n",
    "\u2502   Log Entry                                                 \u2502\n",
    "\u2502       \u2502                                                     \u2502\n",
    "\u2502       \u25bc                                                     \u2502\n",
    "\u2502   Prompt: \"You are a security analyst. Classify this log   \u2502\n",
    "\u2502   entry as MALICIOUS or BENIGN. Explain your reasoning.    \u2502\n",
    "\u2502                                                             \u2502\n",
    "\u2502   Log: Failed login attempt for user admin from IP          \u2502\n",
    "\u2502   185.143.223.47\"                                           \u2502\n",
    "\u2502       \u2502                                                     \u2502\n",
    "\u2502       \u25bc                                                     \u2502\n",
    "\u2502   LLM Response:                                             \u2502\n",
    "\u2502   \"MALICIOUS - Multiple red flags:                         \u2502\n",
    "\u2502    1. Failed login to privileged 'admin' account           \u2502\n",
    "\u2502    2. External IP attempting internal access               \u2502\n",
    "\u2502    3. Pattern consistent with brute force attack\"          \u2502\n",
    "\u2502                                                             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### Comparison at a Glance\n",
    "\n",
    "| Factor | ML | LLM | Winner |\n",
    "|--------|-----|-----|--------|\n",
    "| **1,000 predictions** | <1 second | 5-30 minutes* | ML |\n",
    "| **Cost for 10K logs** | ~$0 | ~$5-50* | ML |\n",
    "| **Novel attack pattern** | May miss | Can reason | LLM |\n",
    "| **Explanation for analyst** | \"Feature X high\" | Full context | LLM |\n",
    "| **Works offline** | Yes | No (API) | ML |\n",
    "\n",
    "*LLM times and costs vary by model, provider, and prompt length. Costs have dropped significantly - check current pricing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Sample Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample log entries for classification\n",
    "# In reality, these would come from your SIEM (Splunk, Elastic, etc.) or log aggregator\n",
    "\n",
    "SAMPLE_LOGS = [\n",
    "    # Malicious logs (label = 1)\n",
    "    {\"log\": \"Failed login attempt for user admin from IP 185.143.223.47\", \"label\": 1},\n",
    "    {\"log\": \"PowerShell execution: -enc JABjAGwAaQBlAG4AdA...\", \"label\": 1},\n",
    "    {\"log\": \"Multiple failed SSH attempts from 45.33.32.156\", \"label\": 1},\n",
    "    {\"log\": \"Suspicious process: cmd.exe spawned by WINWORD.EXE\", \"label\": 1},\n",
    "    {\"log\": \"Outbound connection to known C2 IP 91.219.28.103\", \"label\": 1},\n",
    "    {\"log\": \"Registry modification: HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\", \"label\": 1},\n",
    "    {\"log\": \"Data exfiltration detected: 500MB uploaded to external IP\", \"label\": 1},\n",
    "    {\"log\": \"Mimikatz signature detected in memory\", \"label\": 1},\n",
    "    {\"log\": \"Failed login admin from 10.0.0.1 - brute force pattern\", \"label\": 1},\n",
    "    {\"log\": \"Ransomware behavior: mass file encryption detected\", \"label\": 1},\n",
    "    # Benign logs (label = 0)\n",
    "    {\"log\": \"User john.doe logged in successfully from 192.168.1.50\", \"label\": 0},\n",
    "    {\"log\": \"Scheduled task Windows Update ran successfully\", \"label\": 0},\n",
    "    {\"log\": \"File backup completed: 1,234 files processed\", \"label\": 0},\n",
    "    {\"log\": \"User password changed for account mary.smith\", \"label\": 0},\n",
    "    {\"log\": \"Software update installed: Chrome 120.0.6099.109\", \"label\": 0},\n",
    "    {\"log\": \"Print job completed for user finance_dept\", \"label\": 0},\n",
    "    {\"log\": \"VPN connection established for remote_worker01\", \"label\": 0},\n",
    "    {\"log\": \"Email sent from ceo@company.com to board@company.com\", \"label\": 0},\n",
    "    {\"log\": \"Database backup completed successfully\", \"label\": 0},\n",
    "    {\"log\": \"User logged out: session timeout after 30 minutes\", \"label\": 0},\n",
    "]\n",
    "\n",
    "# Shuffle and split the data\n",
    "import random\n",
    "random.seed(42)\n",
    "shuffled = SAMPLE_LOGS.copy()\n",
    "random.shuffle(shuffled)\n",
    "\n",
    "logs = [item[\"log\"] for item in shuffled]\n",
    "labels = [item[\"label\"] for item in shuffled]\n",
    "\n",
    "print(f\"\ud83d\udcca Dataset: {len(logs)} log entries\")\n",
    "print(f\"   Malicious: {sum(labels)}\")\n",
    "print(f\"   Benign: {len(labels) - sum(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ML Classifier\n",
    "\n",
    "Build a traditional ML classifier using feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Approach: Feature Engineering + Logistic Regression\n",
    "\n",
    "# Define suspicious keywords that often appear in malicious logs\n",
    "SUSPICIOUS_KEYWORDS = [\n",
    "    \"failed\", \"error\", \"unauthorized\", \"denied\", \"blocked\",\n",
    "    \"malicious\", \"suspicious\", \"attack\", \"exploit\", \"inject\",\n",
    "    \"powershell\", \"cmd.exe\", \"mimikatz\", \"ransomware\", \"c2\",\n",
    "    \"encoded\", \"encrypted\", \"exfiltration\", \"brute\"\n",
    "]\n",
    "\n",
    "def extract_features(log: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Extract numerical features from a log entry.\n",
    "\n",
    "    This is the key step in ML - converting text to numbers!\n",
    "\n",
    "    Args:\n",
    "        log: Raw log text\n",
    "\n",
    "    Returns:\n",
    "        List of feature values\n",
    "    \"\"\"\n",
    "    log_lower = log.lower()\n",
    "\n",
    "    features = [\n",
    "        # Feature 1: Count of suspicious keywords\n",
    "        sum(1 for kw in SUSPICIOUS_KEYWORDS if kw in log_lower),\n",
    "\n",
    "        # Feature 2: Contains \"failed\" or \"error\"\n",
    "        1 if \"failed\" in log_lower or \"error\" in log_lower else 0,\n",
    "\n",
    "        # Feature 3: Contains IP address pattern\n",
    "        1 if any(c.isdigit() and \".\" in log for c in log) else 0,\n",
    "\n",
    "        # Feature 4: Log length (longer logs often more suspicious)\n",
    "        len(log) / 100,  # Normalize\n",
    "\n",
    "        # Feature 5: Contains \"admin\" or \"root\"\n",
    "        1 if \"admin\" in log_lower or \"root\" in log_lower else 0,\n",
    "\n",
    "        # Feature 6: Contains encoded/encrypted indicators\n",
    "        1 if \"enc\" in log_lower or \"base64\" in log_lower else 0,\n",
    "    ]\n",
    "\n",
    "    return features\n",
    "\n",
    "# Test feature extraction\n",
    "print(\"Feature extraction examples:\")\n",
    "print(f\"  Malicious log: {extract_features(SAMPLE_LOGS[0]['log'])}\")\n",
    "print(f\"  Benign log: {extract_features(SAMPLE_LOGS[10]['log'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ML classifier\n",
    "\n",
    "# Extract features for all logs\n",
    "X = np.array([extract_features(log) for log in logs])\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split data (use same indices for fair comparison later!)\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X, y, range(len(logs)), test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "ml_model = LogisticRegression(random_state=42)\n",
    "ml_model.fit(X_train, y_train)\n",
    "ml_train_time = time.time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "start_time = time.time()\n",
    "ml_predictions = ml_model.predict(X_test)\n",
    "ml_predict_time = time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "ml_accuracy = accuracy_score(y_test, ml_predictions)\n",
    "ml_precision = precision_score(y_test, ml_predictions, zero_division=0)\n",
    "ml_recall = recall_score(y_test, ml_predictions, zero_division=0)\n",
    "\n",
    "print(\"\ud83d\udcca ML CLASSIFIER RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Training time:    {ml_train_time*1000:.2f}ms\")\n",
    "print(f\"Prediction time:  {ml_predict_time*1000:.2f}ms ({len(y_test)} samples)\")\n",
    "print(f\"Accuracy:         {ml_accuracy:.1%}\")\n",
    "print(f\"Precision:        {ml_precision:.1%}\")\n",
    "print(f\"Recall:           {ml_recall:.1%}\")\n",
    "print(f\"Cost:             $0.00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: LLM Classifier\n",
    "\n",
    "Now let's use an LLM to classify the same logs.\n",
    "\n",
    "> **Note**: This requires an API key. If you don't have one, you can still read the code to understand the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Classification approach\n",
    "# This demonstrates the pattern - you'll need an API key to run\n",
    "\n",
    "CLASSIFICATION_PROMPT = \"\"\"You are a security analyst. Classify this log entry.\n",
    "\n",
    "Log: {log_entry}\n",
    "\n",
    "Respond with EXACTLY one word: MALICIOUS or BENIGN\n",
    "\"\"\"\n",
    "\n",
    "def llm_classify_simulated(log: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulated LLM classification for demo purposes.\n",
    "\n",
    "    In production, this would call an actual LLM API.\n",
    "    This simulation mimics LLM reasoning based on keywords.\n",
    "\n",
    "    Args:\n",
    "        log: Log entry to classify\n",
    "\n",
    "    Returns:\n",
    "        \"MALICIOUS\" or \"BENIGN\"\n",
    "    \"\"\"\n",
    "    # Simulate LLM processing time (real API takes 500-2000ms)\n",
    "    time.sleep(0.1)  # Reduced for demo\n",
    "\n",
    "    # Simple rule-based simulation of LLM reasoning\n",
    "    # Real LLM would understand context much better!\n",
    "    malicious_indicators = [\n",
    "        \"failed\", \"attack\", \"malicious\", \"suspicious\",\n",
    "        \"c2\", \"mimikatz\", \"ransomware\", \"exfiltration\",\n",
    "        \"powershell -enc\", \"spawned by\"\n",
    "    ]\n",
    "\n",
    "    log_lower = log.lower()\n",
    "    if any(ind in log_lower for ind in malicious_indicators):\n",
    "        return \"MALICIOUS\"\n",
    "    return \"BENIGN\"\n",
    "\n",
    "# Test on same test set\n",
    "print(\"\ud83e\udd16 LLM CLASSIFIER (Simulated)\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Use same test indices for fair comparison!\n",
    "test_logs = [logs[i] for i in test_idx]\n",
    "\n",
    "start_time = time.time()\n",
    "llm_predictions = []\n",
    "for log in test_logs:\n",
    "    pred = llm_classify_simulated(log)\n",
    "    llm_predictions.append(1 if pred == \"MALICIOUS\" else 0)\n",
    "llm_predict_time = time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "llm_accuracy = accuracy_score(y_test, llm_predictions)\n",
    "llm_precision = precision_score(y_test, llm_predictions, zero_division=0)\n",
    "llm_recall = recall_score(y_test, llm_predictions, zero_division=0)\n",
    "\n",
    "print(f\"Prediction time:  {llm_predict_time*1000:.2f}ms ({len(y_test)} samples)\")\n",
    "print(f\"Accuracy:         {llm_accuracy:.1%}\")\n",
    "print(f\"Precision:        {llm_precision:.1%}\")\n",
    "print(f\"Recall:           {llm_recall:.1%}\")\n",
    "print(f\"Est. Cost:        ~${len(y_test) * 0.001:.2f} (at $0.001/call)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: The Hybrid Pattern\n",
    "\n",
    "The best approach: **Use both!** ML handles bulk filtering, LLM handles uncertain cases.\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    HYBRID ARCHITECTURE                       \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                             \u2502\n",
    "\u2502   10,000 Log Entries                                        \u2502\n",
    "\u2502           \u2502                                                 \u2502\n",
    "\u2502           \u25bc                                                 \u2502\n",
    "\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                    \u2502\n",
    "\u2502   \u2502   ML FAST FILTER  \u2502  \u2190 Process ALL logs                \u2502\n",
    "\u2502   \u2502   (1 second)      \u2502     Cost: ~$0                      \u2502\n",
    "\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                    \u2502\n",
    "\u2502             \u2502                                               \u2502\n",
    "\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                      \u2502\n",
    "\u2502     \u2502               \u2502                                       \u2502\n",
    "\u2502     \u25bc               \u25bc                                       \u2502\n",
    "\u2502  BENIGN (9,500)  SUSPICIOUS (500)                          \u2502\n",
    "\u2502  Auto-close      \u2502                                          \u2502\n",
    "\u2502                  \u25bc                                          \u2502\n",
    "\u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n",
    "\u2502          \u2502   LLM ANALYSIS    \u2502  \u2190 Only suspicious          \u2502\n",
    "\u2502          \u2502   (5 minutes)     \u2502     Cost: ~$5               \u2502\n",
    "\u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n",
    "\u2502                    \u2502                                        \u2502\n",
    "\u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2502\n",
    "\u2502            \u2502               \u2502                                \u2502\n",
    "\u2502            \u25bc               \u25bc                                \u2502\n",
    "\u2502     False Positive    TRUE THREAT                           \u2502\n",
    "\u2502     Auto-close        \u2192 Human Review                        \u2502\n",
    "\u2502                                                             \u2502\n",
    "\u2502   TOTAL: 10K logs in ~5 min, cost ~$5                      \u2502\n",
    "\u2502   vs LLM-only: 10K logs in ~3 hours, cost ~$100            \u2502\n",
    "\u2502                                                             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid approach: ML filter + LLM for uncertain cases\n",
    "\n",
    "def hybrid_classify(log: str, model, threshold_low=0.3, threshold_high=0.7):\n",
    "    \"\"\"\n",
    "    Hybrid classifier: ML for confident cases, LLM for uncertain ones.\n",
    "\n",
    "    Args:\n",
    "        log: Log entry to classify\n",
    "        model: Trained ML model\n",
    "        threshold_low: Below this = definitely benign\n",
    "        threshold_high: Above this = definitely malicious\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (prediction, used_llm)\n",
    "    \"\"\"\n",
    "    # Step 1: Get ML probability\n",
    "    features = np.array([extract_features(log)])\n",
    "    probability = model.predict_proba(features)[0][1]  # P(malicious)\n",
    "\n",
    "    # Step 2: Decide if confident enough\n",
    "    if probability < threshold_low:\n",
    "        return 0, False  # Definitely benign, ML only\n",
    "    elif probability > threshold_high:\n",
    "        return 1, False  # Definitely malicious, ML only\n",
    "    else:\n",
    "        # Uncertain - use LLM\n",
    "        llm_result = llm_classify_simulated(log)\n",
    "        return 1 if llm_result == \"MALICIOUS\" else 0, True\n",
    "\n",
    "# Test hybrid approach\n",
    "print(\"\ud83d\udd00 HYBRID CLASSIFIER\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "start_time = time.time()\n",
    "hybrid_predictions = []\n",
    "llm_calls = 0\n",
    "\n",
    "for log in test_logs:\n",
    "    pred, used_llm = hybrid_classify(log, ml_model)\n",
    "    hybrid_predictions.append(pred)\n",
    "    if used_llm:\n",
    "        llm_calls += 1\n",
    "\n",
    "hybrid_predict_time = time.time() - start_time\n",
    "\n",
    "# Evaluate\n",
    "hybrid_accuracy = accuracy_score(y_test, hybrid_predictions)\n",
    "hybrid_precision = precision_score(y_test, hybrid_predictions, zero_division=0)\n",
    "hybrid_recall = recall_score(y_test, hybrid_predictions, zero_division=0)\n",
    "\n",
    "print(f\"Prediction time:  {hybrid_predict_time*1000:.2f}ms\")\n",
    "print(f\"LLM calls:        {llm_calls}/{len(y_test)} ({llm_calls/len(y_test)*100:.0f}%)\")\n",
    "print(f\"Accuracy:         {hybrid_accuracy:.1%}\")\n",
    "print(f\"Precision:        {hybrid_precision:.1%}\")\n",
    "print(f\"Recall:           {hybrid_recall:.1%}\")\n",
    "print(f\"Est. Cost:        ~${llm_calls * 0.001:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Summary & Decision Framework\n",
    "\n",
    "### Results Comparison\n",
    "\n",
    "| Approach | Speed | Cost | Accuracy | Best For |\n",
    "|----------|-------|------|----------|----------|\n",
    "| **ML Only** | Fastest | Free | Good | High volume, known patterns |\n",
    "| **LLM Only** | Slowest | Highest | Best | Novel patterns, explanations |\n",
    "| **Hybrid** | Fast | Low | Great | Best of both worlds |\n",
    "\n",
    "### When to Use What\n",
    "\n",
    "```\n",
    "START: What's your constraint?\n",
    "\u2502\n",
    "\u251c\u2500\u25ba Speed/Volume critical (>100/sec)\n",
    "\u2502   \u2514\u2500\u25ba Use ML\n",
    "\u2502\n",
    "\u251c\u2500\u25ba Cost critical (<$0.01/prediction)\n",
    "\u2502   \u2514\u2500\u25ba Use ML\n",
    "\u2502\n",
    "\u251c\u2500\u25ba Need natural language explanation\n",
    "\u2502   \u2514\u2500\u25ba Use LLM (or Hybrid with LLM for uncertain)\n",
    "\u2502\n",
    "\u251c\u2500\u25ba Handling novel/unknown patterns\n",
    "\u2502   \u2514\u2500\u25ba Use LLM (or Hybrid)\n",
    "\u2502\n",
    "\u251c\u2500\u25ba Must work offline/air-gapped\n",
    "\u2502   \u2514\u2500\u25ba Use ML\n",
    "\u2502\n",
    "\u2514\u2500\u25ba Want best of both worlds\n",
    "    \u2514\u2500\u25ba Use Hybrid (ML filter \u2192 LLM verify)\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **ML excels at** high-volume, known-pattern, low-cost scenarios\n",
    "2. **LLM excels at** reasoning, flexibility, and explanation\n",
    "3. **Hybrid is often best** - ML handles bulk, LLM handles edge cases\n",
    "4. **Know your constraints** - speed, cost, accuracy, explainability\n",
    "5. **Measure both** - don't assume, test on your data\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Lab 35**: Deep dive into LLM prompt engineering\n",
    "- **Lab 36**: Build agents that combine ML + LLM\n",
    "- **Lab 23**: Production hybrid detection pipeline"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}